"""Zero-knowledge aware machine learning inference helpers."""
from __future__ import annotations

import hashlib
import json
from typing import Any, Mapping, Tuple

try:  # pragma: no cover - torch may be a lightweight stub in tests
    import torch
except ImportError:  # pragma: no cover
    torch = None  # type: ignore

from .zk_proofs import generate_proof

Witness = Mapping[str, Any]


def _tensor_to_json(tensor: Any) -> str:
    """Serialise a tensor-like value into JSON for stable hashing."""
    if hasattr(tensor, "detach") and callable(tensor.detach):
        tensor = tensor.detach()
    if hasattr(tensor, "cpu") and callable(tensor.cpu):
        tensor = tensor.cpu()
    if hasattr(tensor, "numpy") and callable(tensor.numpy):
        data = tensor.numpy().tolist()
    elif hasattr(tensor, "tolist") and callable(tensor.tolist):
        data = tensor.tolist()
    elif hasattr(tensor, "flatten") and callable(tensor.flatten):
        data = list(tensor.flatten())
    else:
        data = [tensor]
    return json.dumps(data, sort_keys=True)


def build_witness(model: Any, x: Any) -> Witness:
    """Create a witness description from the model and its input tensor.

    Parameters
    ----------
    model:
        Model that produced the inference. Any object with a callable forward
        pass is supported.
    x:
        Input tensor or tensor-like structure used for the inference call.

    Returns
    -------
    Mapping[str, Any]
        Canonical witness dictionary capturing the model class, input shape and
        tensor data type.
    """
    if hasattr(x, "shape"):
        shape = list(getattr(x, "shape"))  # type: ignore[arg-type]
    elif hasattr(x, "flatten") and callable(x.flatten):
        try:
            flattened = x.flatten()
            shape = [len(flattened)]
        except TypeError:  # pragma: no cover - defensive
            shape = []
    else:
        shape = []

    dtype = getattr(x, "dtype", type(x).__name__)

    return {
        "model": type(model).__name__,
        "input_shape": shape,
        "dtype": str(dtype),
    }


def build_statement(prediction: Any, witness: Witness) -> str:
    """Create a canonical statement string for a prediction and witness.

    Parameters
    ----------
    prediction:
        Output tensor produced by the model.
    witness:
        Witness mapping generated by :func:`build_witness`.

    Returns
    -------
    str
        JSON string containing the prediction values and a SHA256 commitment of
        the witness.
    """
    commitment_payload = json.dumps(witness, sort_keys=True, separators=(",", ":"))
    commitment = hashlib.sha256(commitment_payload.encode("utf-8")).hexdigest()
    payload = {
        "prediction": json.loads(_tensor_to_json(prediction)),
        "commitment": commitment,
    }
    return json.dumps(payload, sort_keys=True, separators=(",", ":"))


def zk_infer(model: Any, x: Any) -> Tuple[Any, str]:
    """Run a model inference and generate a placeholder proof.

    The function executes the model (under ``torch.no_grad()`` when available),
    constructs the canonical statement, and calls :func:`generate_proof` to
    obtain the placeholder proof string.

    Parameters
    ----------
    model:
        Callable model implementing a ``forward`` method.
    x:
        Input tensor or tensor-like structure for the inference.

    Returns
    -------
    Tuple[Any, str]
        The raw prediction alongside the placeholder proof string.

    Notes
    -----
    The returned prediction receives an auxiliary ``_zkml_statement`` attribute
    containing the canonical statement string to simplify downstream proof
    verification in tests and demos.
    """
    model_witness = build_witness(model, x)

    if torch is not None and hasattr(torch, "no_grad"):
        with torch.no_grad():  # type: ignore[attr-defined]
            prediction = model(x)
    else:  # pragma: no cover - executed when torch stub lacks no_grad
        prediction = model(x)

    statement = build_statement(prediction, model_witness)
    proof = generate_proof(statement, model_witness)
    try:
        setattr(prediction, "_zkml_statement", statement)
    except Exception:  # pragma: no cover - prediction may be immutable
        pass
    return prediction, proof


__all__ = ["zk_infer", "build_statement", "build_witness"]
